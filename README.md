# World-Lay-off-Data-Cleaning-using-SQL
This project involves the cleaning and preprocessing of global lay-off data using SQL. The dataset was cleaned to remove duplicates, standardize data formats, and ensure consistency across various fields such as company names, dates, and lay-off statistics. Key steps included identifying and removing duplicate records, handling missing values, and optimizing the dataset for further analysis.

The SQL scripts provided in this repository include:

1.Duplicate Removal: A script that identifies and removes duplicate entries based on key columns.
2.Data Standardization: Scripts to standardize data formats, such as date conversions and text formatting.
3.Integrity Checks: Ensuring data consistency and integrity across the dataset.
4.This cleaned dataset can now be utilized for detailed analysis and visualization, providing insights into global lay-off trends.
